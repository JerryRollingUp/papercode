{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# If you think this code is useful. Please cite:\nRen Z, Kong X, Zhang Y, et al. UKSSL: Underlying Knowledge based Semi-Supervised Learning for Medical Image Classification[J]. IEEE Open Journal of Engineering in Medicine and Biology, 2023","metadata":{}},{"cell_type":"code","source":"import math\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport os\nimport pathlib\nimport random\nimport numpy as np\nfrom PIL import Image\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.models import Model, Sequential\nimport tensorflow_addons as tfa\n\nfrom keras import Model\n\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, ConfusionMatrixDisplay, classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T04:30:32.307801Z","iopub.execute_input":"2023-09-26T04:30:32.30815Z","iopub.status.idle":"2023-09-26T04:30:40.67418Z","shell.execute_reply.started":"2023-09-26T04:30:32.308064Z","shell.execute_reply":"2023-09-26T04:30:40.672932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HyperPara","metadata":{}},{"cell_type":"code","source":"project_name = 'UKSSL'\ndataset_dir = '/kaggle/input/leukemia/Original'\nclass_num = len(next(os.walk(dataset_dir))[1])\n\ndata_source = pathlib.Path(dataset_dir)\nlabel_names = sorted(item.name for item in data_source.glob('*/') if item.is_dir())\nlabel_to_index = dict((name,index) for index, name in enumerate(label_names))\nindex_to_label = dict((index,name) for index, name in enumerate(label_names))\nall_image_paths = [str(path) for path in list(data_source.glob('*/*'))]\nrandom.shuffle(all_image_paths)\nall_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n\ndataset_size = len(all_image_paths)\n\nprint('img indices: ', label_names)\nprint('img num: ', dataset_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:30:40.67643Z","iopub.execute_input":"2023-09-26T04:30:40.677317Z","iopub.status.idle":"2023-09-26T04:30:42.193307Z","shell.execute_reply.started":"2023-09-26T04:30:40.677277Z","shell.execute_reply":"2023-09-26T04:30:42.192274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset hyperparameters\nunlabeled_ratio = 0.675\nlabeled_ratio = 0.225\ntest_ratio = 0.1\n\nunlabeled_dataset_size = int(dataset_size*unlabeled_ratio)\nlabeled_dataset_size = int(dataset_size*labeled_ratio)\ntest_dataset_size = dataset_size-unlabeled_dataset_size-labeled_dataset_size\n\nprint('unlabeled size: ',unlabeled_dataset_size,'labeled size: ',labeled_dataset_size,'test size: ',test_dataset_size)\nimage_size = 96\nimage_channels = 3\n\n# Algorithm hyperparameters\nnum_epochs = 200\nbatch_size = 500  # Corresponds to 200 steps per epoch\nwidth = 128\ntemperature = 0.1\n# Stronger augmentations for contrastive, weaker ones for supervised training\ncontrastive_augmentation = {\"min_area\": 0.25, \"brightness\": 0.6, \"jitter\": 0.2}\nclassification_augmentation = {\"min_area\": 0.75, \"brightness\": 0.3, \"jitter\": 0.1}","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:57:27.177896Z","iopub.execute_input":"2023-09-26T05:57:27.178286Z","iopub.status.idle":"2023-09-26T05:57:27.187778Z","shell.execute_reply.started":"2023-09-26T05:57:27.178251Z","shell.execute_reply":"2023-09-26T05:57:27.186117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hypare for vit\ntransformer_layers = 1 # ori 8\ninput_shape = (96,96,3)\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nnum_heads = 4\nprojection_dim = 64\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\nmlp_head_units = [2048,1024,512,256,128]\nnum_classes = class_num","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:30:42.208256Z","iopub.execute_input":"2023-09-26T04:30:42.208619Z","iopub.status.idle":"2023-09-26T04:30:42.224638Z","shell.execute_reply.started":"2023-09-26T04:30:42.208578Z","shell.execute_reply":"2023-09-26T04:30:42.223732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show some imgs\nfrom random import seed\n\nplt.figure(figsize=(10,10))\nfor n in range(1,5):\n    image_path = random.choice(all_image_paths)\n    img_data = np.asarray(Image.open(image_path))\n    img_label = [pathlib.Path(image_path).parent.name]\n    # display.display(display.Image(image_path))\n    plt.subplot(2,2,n)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(img_label)\n    plt.imshow(img_data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:30:42.226249Z","iopub.execute_input":"2023-09-26T04:30:42.226655Z","iopub.status.idle":"2023-09-26T04:30:42.743175Z","shell.execute_reply.started":"2023-09-26T04:30:42.226618Z","shell.execute_reply":"2023-09-26T04:30:42.742293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"tep = []\nfor path in all_image_paths:\n    feature=tf.io.read_file(path)\n    #解码图片\n    feature = tf.image.decode_jpeg(feature,channels=3)\n    #重新设置大小\n    feature = tf.image.resize(feature, size=[96, 96])\n    tep.append(tf.reshape(feature, shape=[1,96,96,3]))\nall_images = tf.concat(tep,0)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:30:42.744236Z","iopub.execute_input":"2023-09-26T04:30:42.744596Z","iopub.status.idle":"2023-09-26T04:31:16.11297Z","shell.execute_reply.started":"2023-09-26T04:30:42.744549Z","shell.execute_reply":"2023-09-26T04:31:16.111875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 元组被解压缩到映射函数的位置参数中\ndef load_and_preprocess_from_path_label(path, label):\n\treturn load_and_process_image(path), label\n \ndataset_all = tf.data.Dataset.from_tensor_slices((all_images,all_image_labels)) # as_supervised=True with label. True with label.","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:57:36.84391Z","iopub.execute_input":"2023-09-26T05:57:36.844314Z","iopub.status.idle":"2023-09-26T05:57:36.863738Z","shell.execute_reply.started":"2023-09-26T05:57:36.844279Z","shell.execute_reply":"2023-09-26T05:57:36.862551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create unlabeled, labeled, test datasets\nunlabeled_train_datasets = dataset_all.take(unlabeled_dataset_size)\nlabeled_train_datasets = dataset_all.skip(unlabeled_dataset_size).take(labeled_dataset_size)\ntrain_datasets_ssl = dataset_all.take(unlabeled_dataset_size+labeled_dataset_size)\ntest_datasets = dataset_all.skip(unlabeled_dataset_size+labeled_dataset_size)\nprint('unlabeled_train_datasets: ',tf.data.experimental.cardinality(unlabeled_train_datasets).numpy(),\n      'labeled_train_datasets: ',tf.data.experimental.cardinality(labeled_train_datasets).numpy(),\n      'ssl_train_datasets: ',tf.data.experimental.cardinality(train_datasets_ssl).numpy(),\n      'test_datasets: ',tf.data.experimental.cardinality(test_datasets).numpy()\n     )","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:57:38.707769Z","iopub.execute_input":"2023-09-26T05:57:38.708144Z","iopub.status.idle":"2023-09-26T05:57:38.719568Z","shell.execute_reply.started":"2023-09-26T05:57:38.70811Z","shell.execute_reply":"2023-09-26T05:57:38.718447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset():\n    # Labeled and unlabeled samples are loaded synchronously\n    # with batch sizes selected accordingly\n    steps_per_epoch = (unlabeled_dataset_size + labeled_dataset_size) // batch_size\n    unlabeled_batch_size = unlabeled_dataset_size // steps_per_epoch\n    labeled_batch_size = labeled_dataset_size // steps_per_epoch\n    print(\n        f\"batch size is {unlabeled_batch_size} (unlabeled) + {labeled_batch_size} (labeled)\"\n    )\n\n    unlabeled_train_dataset = (\n        unlabeled_train_datasets\n        .shuffle(buffer_size=10 * unlabeled_batch_size)\n        .batch(unlabeled_batch_size)\n    )\n    labeled_train_dataset = (\n        labeled_train_datasets\n        .shuffle(buffer_size=10 * labeled_batch_size)\n        .batch(labeled_batch_size)\n    )\n    \n    train_datasets_ssl1 = (\n        train_datasets_ssl\n        .shuffle(buffer_size=10 * batch_size)\n        .batch(batch_size)\n    )\n    test_dataset = (\n        test_datasets\n        .batch(batch_size)\n        .prefetch(buffer_size=tf.data.AUTOTUNE)\n    )\n\n    # Labeled and unlabeled datasets are zipped together\n    train_dataset = tf.data.Dataset.zip(\n        (unlabeled_train_dataset, labeled_train_dataset)\n    ).prefetch(buffer_size=tf.data.AUTOTUNE)\n\n    return train_dataset, labeled_train_dataset, train_datasets_ssl1, test_dataset\n\n\n# Load STL10 dataset\ntrain_dataset, labeled_train_dataset, train_datasets_ssl, test_dataset = prepare_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:57:41.034954Z","iopub.execute_input":"2023-09-26T05:57:41.035353Z","iopub.status.idle":"2023-09-26T05:57:41.052238Z","shell.execute_reply.started":"2023-09-26T05:57:41.035314Z","shell.execute_reply":"2023-09-26T05:57:41.051009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train_dataset: ',tf.data.experimental.cardinality(train_dataset).numpy(),\n      'labeled_train_dataset: ',tf.data.experimental.cardinality(labeled_train_dataset).numpy(),\n      'test_dataset: ',tf.data.experimental.cardinality(test_dataset).numpy()\n     )","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:32:07.206667Z","iopub.execute_input":"2023-09-26T05:32:07.207049Z","iopub.status.idle":"2023-09-26T05:32:07.214452Z","shell.execute_reply.started":"2023-09-26T05:32:07.207017Z","shell.execute_reply":"2023-09-26T05:32:07.213254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image augmentations","metadata":{}},{"cell_type":"code","source":"# Distorts the color distibutions of images\nclass RandomColorAffine(layers.Layer):\n    def __init__(self, brightness=0, jitter=0, **kwargs):\n        super().__init__(**kwargs)\n\n        self.brightness = brightness\n        self.jitter = jitter\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"brightness\": self.brightness, \"jitter\": self.jitter})\n        return config\n\n    def call(self, images, training=True):\n        if training:\n            batch_size = tf.shape(images)[0]\n\n            # Same for all colors\n            brightness_scales = 1 + tf.random.uniform(\n                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n            )\n            # Different for all colors\n            jitter_matrices = tf.random.uniform(\n                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n            )\n\n            color_transforms = (\n                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n                + jitter_matrices\n            )\n            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n        return images\n\n\n# Image augmentation module\ndef get_augmenter(min_area, brightness, jitter):\n    zoom_factor = 1.0 - math.sqrt(min_area)\n    return keras.Sequential(\n        [\n            keras.Input(shape=(image_size, image_size, image_channels)),\n            layers.Rescaling(1 / 255),\n            layers.RandomFlip(\"horizontal\"),\n            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n            RandomColorAffine(brightness, jitter),\n        ]\n    )\n\n\ndef visualize_augmentations(num_images):\n    # Sample a batch from a dataset\n    images = next(iter(train_dataset))[0][0][:num_images]\n    # Apply augmentations\n    augmented_images = zip(\n        images,\n        get_augmenter(**classification_augmentation)(images),\n        get_augmenter(**contrastive_augmentation)(images),\n        get_augmenter(**contrastive_augmentation)(images),\n    )\n    row_titles = [\n        \"Original:\",\n        \"Weakly augmented:\",\n        \"Strongly augmented:\",\n        \"Strongly augmented:\",\n    ]\n    plt.figure(figsize=(num_images * 2.2, 4 * 2.2), dpi=100)\n    for column, image_row in enumerate(augmented_images):\n        for row, image in enumerate(image_row):\n            plt.subplot(4, num_images, row * num_images + column + 1)\n            plt.imshow(image)\n            if column == 0:\n                plt.title(row_titles[row], loc=\"left\")\n            plt.axis(\"off\")\n    plt.tight_layout()\n\n\nvisualize_augmentations(num_images=8)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:16.482609Z","iopub.execute_input":"2023-09-26T04:31:16.483069Z","iopub.status.idle":"2023-09-26T04:31:21.212464Z","shell.execute_reply.started":"2023-09-26T04:31:16.483033Z","shell.execute_reply":"2023-09-26T04:31:21.211563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoder architecture\n","metadata":{}},{"cell_type":"code","source":"# def LeNet5():\n#     model = Sequential()\n#     model.add(layers.Input(shape=(96, 96, 3)))\n#     model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"))\n#     model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n#     model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n#     model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n#     model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n#     model.add(layers.Flatten())\n#     model.add(layers.Dense(128,activation='relu'))\n  \n#     return model\n\n# encoder = LeNet5()\n\n# def get_encoder():\n#     return encoder","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.213834Z","iopub.execute_input":"2023-09-26T04:31:21.215066Z","iopub.status.idle":"2023-09-26T04:31:21.220951Z","shell.execute_reply.started":"2023-09-26T04:31:21.215027Z","shell.execute_reply":"2023-09-26T04:31:21.219741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.222752Z","iopub.execute_input":"2023-09-26T04:31:21.223194Z","iopub.status.idle":"2023-09-26T04:31:21.233938Z","shell.execute_reply.started":"2023-09-26T04:31:21.223158Z","shell.execute_reply":"2023-09-26T04:31:21.23293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.235494Z","iopub.execute_input":"2023-09-26T04:31:21.235921Z","iopub.status.idle":"2023-09-26T04:31:21.246152Z","shell.execute_reply.started":"2023-09-26T04:31:21.235793Z","shell.execute_reply":"2023-09-26T04:31:21.245052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.247787Z","iopub.execute_input":"2023-09-26T04:31:21.24811Z","iopub.status.idle":"2023-09-26T04:31:21.261525Z","shell.execute_reply.started":"2023-09-26T04:31:21.248078Z","shell.execute_reply":"2023-09-26T04:31:21.260518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_vit_classifier():\n    inputs = layers.Input(shape=input_shape)\n    # Augment data.\n    # augmented = data_augmentation(inputs)\n    # Create patches.\n    patches = Patches(patch_size)(inputs)\n    # Encode patches.\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n\n    # Create multiple layers of the Transformer block.\n    for _ in range(transformer_layers):\n        # Layer normalization 1.\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n        # Create a multi-head attention layer.\n        attention_output = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n        )(x1, x1)\n        # Skip connection 1.\n        x2 = layers.Add()([attention_output, encoded_patches])\n        # Layer normalization 2.\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        # MLP.\n        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n        # Skip connection 2.\n        encoded_patches = layers.Add()([x3, x2])\n\n    # Create a [batch_size, projection_dim] tensor.\n    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n    representation = layers.Flatten()(representation)\n    representation = layers.Dense(128,activation='gelu')(representation)\n    # Add MLP.\n#     features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n    # Classify outputs.\n    # logits = layers.Dense(num_classes)(features)\n    # Create the Keras model.\n    model = keras.Model(inputs=inputs, outputs=representation)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.26305Z","iopub.execute_input":"2023-09-26T04:31:21.263763Z","iopub.status.idle":"2023-09-26T04:31:21.277062Z","shell.execute_reply.started":"2023-09-26T04:31:21.263728Z","shell.execute_reply":"2023-09-26T04:31:21.275906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = create_vit_classifier()\ndef get_encoder():\n    return encoder","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.278562Z","iopub.execute_input":"2023-09-26T04:31:21.279238Z","iopub.status.idle":"2023-09-26T04:31:21.574686Z","shell.execute_reply.started":"2023-09-26T04:31:21.279181Z","shell.execute_reply":"2023-09-26T04:31:21.5737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.576099Z","iopub.execute_input":"2023-09-26T04:31:21.576494Z","iopub.status.idle":"2023-09-26T04:31:21.585442Z","shell.execute_reply.started":"2023-09-26T04:31:21.576456Z","shell.execute_reply":"2023-09-26T04:31:21.584333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Self-supervised model for contrastive pretraining\n","metadata":{}},{"cell_type":"code","source":"# Define the contrastive model with model-subclassing\nclass ContrastiveModel(keras.Model):\n    def call(self, inputs):\n        x = self.encoder(inputs)\n        x = self.projection_head(x)\n        x = self.linear_probe(x)\n        return x\n    \n    def __init__(self):\n        super().__init__()\n\n        self.temperature = temperature\n        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n        self.classification_augmenter = get_augmenter(**classification_augmentation)\n        self.encoder = get_encoder()\n        # Non-linear MLP as projection head\n        self.projection_head = keras.Sequential(\n            [\n                keras.Input(shape=(width,)),\n                layers.Dense(width, activation=\"relu\"),\n                layers.Dense(width),\n            ],\n            name=\"projection_head\",\n        )\n        # Single dense layer for linear probing\n        self.linear_probe = keras.Sequential(\n            [layers.Input(shape=(width,)), layers.Dense(class_num)], name=\"linear_probe\"\n        )\n\n        self.encoder.summary()\n        self.projection_head.summary()\n        self.linear_probe.summary()\n\n    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n        super().compile(**kwargs)\n\n        self.contrastive_optimizer = contrastive_optimizer\n        self.probe_optimizer = probe_optimizer\n\n        # self.contrastive_loss will be defined as a method\n        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n            name=\"c_acc\"\n        )\n        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n\n    @property\n    def metrics(self):\n        return [\n            self.contrastive_loss_tracker,\n            self.contrastive_accuracy,\n            self.probe_loss_tracker,\n            self.probe_accuracy,\n        ]\n\n    def contrastive_loss(self, projections_1, projections_2):\n        # InfoNCE loss (information noise-contrastive estimation)\n        # NT-Xent loss (normalized temperature-scaled cross entropy)\n\n        # Cosine similarity: the dot product of the l2-normalized feature vectors\n        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n        similarities = (\n            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n        )\n\n        # The similarity between the representations of two augmented views of the\n        # same image should be higher than their similarity with other views\n        batch_size = tf.shape(projections_1)[0]\n        contrastive_labels = tf.range(batch_size)\n        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n        self.contrastive_accuracy.update_state(\n            contrastive_labels, tf.transpose(similarities)\n        )\n\n        # The temperature-scaled similarities are used as logits for cross-entropy\n        # a symmetrized version of the loss is used here\n        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n            contrastive_labels, similarities, from_logits=True\n        )\n        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n            contrastive_labels, tf.transpose(similarities), from_logits=True\n        )\n        return (loss_1_2 + loss_2_1) / 2\n\n    def train_step(self, data):\n        (unlabeled_images, _), (labeled_images, labels) = data\n\n        # Both labeled and unlabeled images are used, without labels\n        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n        # Each image is augmented twice, differently\n        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n        with tf.GradientTape() as tape:\n            features_1 = self.encoder(augmented_images_1, training=True)\n            features_2 = self.encoder(augmented_images_2, training=True)\n            # The representations are passed through a projection mlp\n            projections_1 = self.projection_head(features_1, training=True)\n            projections_2 = self.projection_head(features_2, training=True)\n            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n        gradients = tape.gradient(\n            contrastive_loss,\n            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n        )\n        self.contrastive_optimizer.apply_gradients(\n            zip(\n                gradients,\n                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n            )\n        )\n        self.contrastive_loss_tracker.update_state(contrastive_loss)\n\n        # Labels are only used in evalutation for an on-the-fly logistic regression\n        preprocessed_images = self.classification_augmenter(\n            labeled_images, training=True\n        )\n        with tf.GradientTape() as tape:\n            # the encoder is used in inference mode here to avoid regularization\n            # and updating the batch normalization paramers if they are used\n            features = self.encoder(preprocessed_images, training=False)\n            class_logits = self.linear_probe(features, training=True)\n            probe_loss = self.probe_loss(labels, class_logits)\n        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n        self.probe_optimizer.apply_gradients(\n            zip(gradients, self.linear_probe.trainable_weights)\n        )\n        self.probe_loss_tracker.update_state(probe_loss)\n        self.probe_accuracy.update_state(labels, class_logits)\n\n        return {m.name: m.result() for m in self.metrics}\n\n    def test_step(self, data):\n        labeled_images, labels = data\n\n        # For testing the components are used with a training=False flag\n        preprocessed_images = self.classification_augmenter(\n            labeled_images, training=False\n        )\n        features = self.encoder(preprocessed_images, training=False)\n        class_logits = self.linear_probe(features, training=False)\n        probe_loss = self.probe_loss(labels, class_logits)\n        self.probe_loss_tracker.update_state(probe_loss)\n        self.probe_accuracy.update_state(labels, class_logits)\n\n        # Only the probe metrics are logged at test time\n        return {m.name: m.result() for m in self.metrics[2:]}\n\n\n# Contrastive pretraining\npretraining_model = ContrastiveModel()\npretraining_model.compile(\n    contrastive_optimizer=keras.optimizers.Adam(),\n    probe_optimizer=keras.optimizers.Adam(),\n)\n\npretraining_history = pretraining_model.fit(\n    train_dataset, epochs=num_epochs, validation_data=test_dataset\n)\nprint(\n    \"Maximal validation accuracy: {:.2f}%\".format(\n        max(pretraining_history.history[\"val_p_acc\"]) * 100\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:31:21.587155Z","iopub.execute_input":"2023-09-26T04:31:21.587732Z","iopub.status.idle":"2023-09-26T04:45:27.772838Z","shell.execute_reply.started":"2023-09-26T04:31:21.587695Z","shell.execute_reply":"2023-09-26T04:45:27.771701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Supervised finetuning of the pretrained encoder\n","metadata":{}},{"cell_type":"code","source":"# v4\ndef ft_model(pretraining_model):\n    input = layers.Input(shape=(image_size, image_size, image_channels))\n    x = get_augmenter(**classification_augmentation)(input)\n    x = pretraining_model.encoder(x)\n    x = layers.Dense(256,activation='relu')(x)\n    x = layers.Dense(256,activation='relu')(x)\n    x = layers.Dense(256,activation='relu')(x)\n    \n    x = layers.Dense(512,activation='relu')(x)\n    x = layers.Dense(512,activation='relu')(x)\n\n    x = layers.Dense(1024,activation='relu')(x)\n    x = layers.Dense(1024,activation='relu')(x)\n    \n    x = layers.Dense(512,activation='relu')(x)\n    x = layers.Dense(512,activation='relu')(x)\n\n    x = layers.Dense(256,activation='relu')(x)\n    x = layers.Dense(256,activation='relu')(x)\n    x = layers.Dense(256,activation='relu')(x)\n\n\n    output = layers.Dense(class_num)(x)\n    finetuning_model = Model(inputs=input, outputs = output,name=\"finetuning_{}\".format(pretraining_model.encoder.name))\n    \n    return finetuning_model","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:45:27.777168Z","iopub.execute_input":"2023-09-26T04:45:27.777576Z","iopub.status.idle":"2023-09-26T04:45:27.789962Z","shell.execute_reply.started":"2023-09-26T04:45:27.777537Z","shell.execute_reply":"2023-09-26T04:45:27.788525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finetuning_model = ft_model(pretraining_model)\nfinetuning_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T04:45:27.791831Z","iopub.execute_input":"2023-09-26T04:45:27.792217Z","iopub.status.idle":"2023-09-26T04:45:28.307194Z","shell.execute_reply.started":"2023-09-26T04:45:27.792165Z","shell.execute_reply":"2023-09-26T04:45:28.306162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finetuning_model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n)\n# labeled_train_dataset train_datasets_ssl\nfinetuning_history = finetuning_model.fit(\n    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset\n)\nprint(\n    \"Maximal validation accuracy: {:.2f}%\".format(\n        max(finetuning_history.history[\"val_acc\"]) * 100\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:58:05.68842Z","iopub.execute_input":"2023-09-26T05:58:05.688795Z","iopub.status.idle":"2023-09-26T06:03:47.143631Z","shell.execute_reply.started":"2023-09-26T05:58:05.688764Z","shell.execute_reply":"2023-09-26T06:03:47.142533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Print the results","metadata":{}},{"cell_type":"code","source":"# get all labels of test dataset.\n_, true_labels = tuple(zip(*test_dataset))\n# true_labels = np.array(true_labels).flatten()\ntrue_labels = np.hstack(true_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:03:47.147691Z","iopub.execute_input":"2023-09-26T06:03:47.148076Z","iopub.status.idle":"2023-09-26T06:03:47.574673Z","shell.execute_reply.started":"2023-09-26T06:03:47.148037Z","shell.execute_reply":"2023-09-26T06:03:47.573441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supervised Fine-tuned model","metadata":{}},{"cell_type":"code","source":"preds_f = finetuning_model.predict(test_dataset)\npred_results_f = np.argmax(preds_f, axis=1)\npre_f, rec_f, f1s_f, _ = precision_recall_fscore_support(true_labels, pred_results_f, average='macro')\nprint('Fine-tuned model performance: ')\nprint(classification_report(true_labels, pred_results_f, digits=3))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:03:47.576382Z","iopub.execute_input":"2023-09-26T06:03:47.576771Z","iopub.status.idle":"2023-09-26T06:03:48.745967Z","shell.execute_reply.started":"2023-09-26T06:03:47.576734Z","shell.execute_reply":"2023-09-26T06:03:48.744922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"50%\nFine-tuned model performance: \n              precision    recall  f1-score   support\n\n           0      1.000     0.731     0.844        52\n           1      0.879     1.000     0.936       109\n           2      1.000     0.989     0.994        87\n           3      1.000     1.000     1.000        78\n\n    accuracy                          0.954       326\n   macro avg      0.970     0.930     0.944       326\nweighted avg      0.960     0.954     0.952       326\n\n25%\n\nFine-tuned model performance: \n              precision    recall  f1-score   support\n\n           0      0.604     0.558     0.580        52\n           1      0.756     0.826     0.789       109\n           2      0.976     0.943     0.960        88\n           3      1.000     0.962     0.980        78\n\n    accuracy                          0.847       327\n   macro avg      0.834     0.822     0.827       327\nweighted avg      0.849     0.847     0.847       327\n\n10%\n\nFine-tuned model performance: \n              precision    recall  f1-score   support\n\n           0      0.600     0.577     0.588        52\n           1      0.721     0.807     0.762       109\n           2      1.000     0.851     0.919        87\n           3      0.975     1.000     0.987        78\n\n    accuracy                          0.828       326\n   macro avg      0.824     0.809     0.814       326\nweighted avg      0.837     0.828     0.830       326\n\n1%\n\nFine-tuned model performance: \n              precision    recall  f1-score   support\n\n           0      0.000     0.000     0.000        52\n           1      0.671     0.881     0.762       109\n           2      0.743     0.862     0.798        87\n           3      0.951     1.000     0.975        78\n\n    accuracy                          0.764       326\n   macro avg      0.591     0.686     0.634       326\nweighted avg      0.650     0.764     0.701       326","metadata":{}},{"cell_type":"markdown","source":"# Comparison against the baseline\n","metadata":{}},{"cell_type":"code","source":"# The classification accuracies of the baseline and the pretraining + finetuning process:\ndef plot_training_curves(pretraining_history, finetuning_history):\n    for metric_key, metric_name in zip([\"acc\", \"loss\"], [\"accuracy\", \"loss\"]):\n        plt.figure(figsize=(8, 5), dpi=100)\n        plt.plot(\n            pretraining_history.history[f\"val_p_{metric_key}\"],\n            label=\"self-supervised pretraining\",\n        )\n        plt.plot(\n            finetuning_history.history[f\"val_{metric_key}\"],\n            label=\"supervised finetuning\",\n        )\n        plt.legend()\n        plt.title(f\"Classification {metric_name} during training\")\n        plt.xlabel(\"epochs\")\n        plt.ylabel(f\"validation {metric_name}\")\n\n\nplot_training_curves(pretraining_history, finetuning_history)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:03:48.748462Z","iopub.execute_input":"2023-09-26T06:03:48.748854Z","iopub.status.idle":"2023-09-26T06:03:49.612448Z","shell.execute_reply.started":"2023-09-26T06:03:48.748815Z","shell.execute_reply":"2023-09-26T06:03:49.611365Z"},"trusted":true},"execution_count":null,"outputs":[]}]}